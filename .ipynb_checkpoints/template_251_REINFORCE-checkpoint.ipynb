{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b961f69b",
   "metadata": {
    "id": "b961f69b"
   },
   "source": [
    "# 251. REINFORCE Algorithm\n",
    "\n",
    "- Monte-Carlo method를 통해 구한 episodic sample 의 estimated return을 이용하여 policy parameter 𝜃를 update해 나가는 기법\n",
    "\n",
    "- REINFORCE 갱신 규칙\n",
    "\n",
    "$$\\Delta\\theta_t = \\alpha\\nabla_\\theta\\log{\\pi_\\theta}(s, a)G_t$$\n",
    "\n",
    "- 따라서, Loss function 은\n",
    "$$-G_t\\log{\\pi_\\theta}(s, a)$$\n",
    "\n",
    "```\n",
    "                log_prob = torch.log(pi(state_tensor))\n",
    "                selected_log_probs = reward_tensor * \\\n",
    "                        torch.gather(log_prob, 1, action_tensor.unsqueeze(1)).squeeze()\n",
    "                loss = -1 * selected_log_probs.mean()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c9cb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # install dependencies needed for recording videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd33883",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5175f9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "qCER-H6cO7Rh",
   "metadata": {
    "id": "qCER-H6cO7Rh"
   },
   "source": [
    "<img src=\"https://miro.medium.com/max/1400/1*4RncZNj1ij5A5eMJpexhrw.png\" width=700/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6814aa4c",
   "metadata": {
    "id": "6814aa4c"
   },
   "source": [
    "### 환경 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c639de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#env = gym.make('LunarLander-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420cc627",
   "metadata": {
    "id": "420cc627"
   },
   "source": [
    "### Policy Network 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab41a2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A differentiable policy parameterization pi(a|s,theta)\n",
    "class PolicyNetwork(nn.Module):\n",
    "    def __init__(self, input_dims, n_actions):\n",
    "    def forward(self, state):\n",
    "#Initialize the parameters theta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cce56db",
   "metadata": {
    "id": "0cce56db"
   },
   "source": [
    "### hyper-parameters 설정, reward 계산 도우미 함수 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f197b903",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select step-size parameters 0<alpha<1\n",
    "#Choose discount rate 0<gamma<1\n",
    "#Chose max number of episodes N\n",
    "# Choose number of episodes to batch together for an update K >= 1\n",
    "# rendering = True\n",
    "def discount_rewards(rewards):\n",
    "    # cumsum의 배열 방향을 반대로 한 다음 원래 순서로 되돌립니다.\n",
    "    # return Returns - Returns.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d9655c",
   "metadata": {
    "id": "48d9655c"
   },
   "source": [
    "### main algorithm 작성 / Train\n",
    "- `CartPole-v0`의 경우 train 약 10 분 소요\n",
    "- `LunarLander-v2` 의 경우 train 시간 약 1 시간 소요\n",
    "- 시간 부족할 경우 이미 훈련된  `251_REINFORCE_LunarLander-V2.pth` 를 load 하여 시각화 Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209099e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# While episode n < N do: (training의 안정성 제고)\n",
    "    # for K batches do:\n",
    "    # Generate an episode s0, a0, r0,...st,at,rt following policy pi(a|s,theta)\n",
    "#         if rendering and (episode > N * 0.98):\n",
    "#             env.render()\n",
    "            # for each step in the eposide(t), discount reward do:\n",
    "            # G_t = sum from t=1 to t=T {gamma^t * R_t}\n",
    "            # If batch is complete, update network\n",
    "                # Calculate policy loss for all episides in the batch\n",
    "                # L(theta) = -1/m sum(ln(G_t pi(a|s,theta)))))\n",
    "                # Update the policy:\n",
    "                # theta <- theta + alpha * grad[L(theat)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b58730",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(pi.state_dict(), '251_REINFORCE_LunarLander-V2.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8840559f",
   "metadata": {
    "id": "8840559f"
   },
   "source": [
    "### reward 변화 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b0a758",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4qxsHHDlOW82",
   "metadata": {
    "id": "4qxsHHDlOW82"
   },
   "source": [
    "### 이미 학습되어 저장된 model load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b7ff45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f5d550b",
   "metadata": {
    "id": "2f5d550b"
   },
   "source": [
    "### Animate it with Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab20f702",
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_mp4(videopath: str) -> str:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441f43da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd1dfab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443279a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
